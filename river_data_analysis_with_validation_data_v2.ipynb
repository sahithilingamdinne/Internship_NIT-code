{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5A_whsyZedvf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv1D, Flatten, Dense,Dropout, Activation\n",
        "from keras.layers import SimpleRNN, LSTM, Dense,GRU,Bidirectional\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "from sklearn.metrics.pairwise import rbf_kernel\n",
        "from sklearn.linear_model import Ridge\n",
        "from scipy.stats import pearsonr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k-4LZP4tCX24"
      },
      "outputs": [],
      "source": [
        "# Load the datta\n",
        "df = pd.read_csv('/content/Ganga River_updated.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wzauOF3MCbhL"
      },
      "outputs": [],
      "source": [
        "# Filter rows for each station\n",
        "row = df[df['Station']==\"Uttar Pradesh\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 765
        },
        "id": "dLcsuvHjKQCZ",
        "outputId": "8adab83d-a580-4178-cec9-6514df9b20cb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "# Identify outliers using a boxplot\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(data=row[['Temperature (C)','pH','Conductivity (?Siemens/cm)','BOD (mg/L)']])\n",
        "plt.title('Boxplot of Selected Features')\n",
        "plt.show()\n",
        "# Iterate through each column in the selected features\n",
        "for column in ['Temperature (C)','pH','Conductivity (?Siemens/cm)','BOD (mg/L)']:\n",
        "    # Calculate quartiles and IQR\n",
        "    q1 = row[column].quantile(0.25)\n",
        "    q3 = row[column].quantile(0.75)\n",
        "    iqr = q3 - q1\n",
        "    # Define lower and upper bounds for outliers\n",
        "    lower_bound = q1 - 1.5 * iqr\n",
        "    upper_bound = q3 + 1.5 * iqr\n",
        "    # Identify outliers and replace them with the mean\n",
        "    outliers = (row[column] < lower_bound) | (row[column] > upper_bound)\n",
        "    mean_value = row.loc[~outliers, column].mean()\n",
        "    row.loc[outliers, column] = mean_value\n",
        "# Verify changes\n",
        "plt.figure(figsize=(6, 4))\n",
        "sns.boxplot(data=row[['Temperature (C)','pH','Conductivity (?Siemens/cm)','BOD (mg/L)']])  # Replace 'feature1', 'feature2', 'feature3' with your actual column names\n",
        "plt.title('Boxplot after Handling Outliers')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Trfr4Hj4LAMb",
        "outputId": "95bd7a91-5829-42e4-a7e4-25bbf078edba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Station  Year  Temperature (C)    pH  Conductivity (?Siemens/cm)  \\\n",
            "160  West Bengal  2013             20.0  7.40                       230.0   \n",
            "161  West Bengal  2013             32.0  7.80                       358.0   \n",
            "162  West Bengal  2014             16.0  7.50                       193.0   \n",
            "163  West Bengal  2014             32.0  8.10                       385.0   \n",
            "164  West Bengal  2015             19.0  7.50                       213.0   \n",
            "..           ...   ...              ...   ...                         ...   \n",
            "249  West Bengal  2018             32.0  8.40                       442.0   \n",
            "250  West Bengal  2019             21.0  7.00                       214.0   \n",
            "251  West Bengal  2019             32.0  8.80                       372.0   \n",
            "252  West Bengal  2020             18.0  7.70                       228.0   \n",
            "253  West Bengal  2020             34.0  8.84                       384.0   \n",
            "\n",
            "     BOD (mg/L)  Total coliform  D.O. (mg/L)  \n",
            "160         4.5             400         11.0  \n",
            "161         6.9           16000          6.0  \n",
            "162         1.0            3000         11.0  \n",
            "163         8.7         1600000          4.4  \n",
            "164         0.4           13000          9.8  \n",
            "..          ...             ...          ...  \n",
            "249        10.1          280000          3.8  \n",
            "250         1.1            7000         11.5  \n",
            "251         6.1          500000          4.3  \n",
            "252         1.3           17000         12.5  \n",
            "253         4.4          300000          4.2  \n",
            "\n",
            "[94 rows x 8 columns]\n"
          ]
        }
      ],
      "source": [
        "print(row)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358
        },
        "id": "uZsGkOxeJiAC",
        "outputId": "91d8017e-e5b7-462b-a8d0-528f08909253"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-ff23eb10992e>:2: FutureWarning: The default value of numeric_only in DataFrame.corr is deprecated. In a future version, it will default to False. Select only valid columns or specify the value of numeric_only to silence this warning.\n",
            "  df.corr(method='pearson')\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                Year  Temperature (C)        pH  \\\n",
              "Year                        1.000000         0.075839 -0.034884   \n",
              "Temperature (C)             0.075839         1.000000  0.763918   \n",
              "pH                         -0.034884         0.763918  1.000000   \n",
              "Conductivity (?Siemens/cm)  0.052047         0.736047  0.630247   \n",
              "BOD (mg/L)                 -0.124775         0.655034  0.581513   \n",
              "Total coliform             -0.034752         0.202834  0.162319   \n",
              "D.O. (mg/L)                 0.040632        -0.834528 -0.638366   \n",
              "\n",
              "                            Conductivity (?Siemens/cm)  BOD (mg/L)  \\\n",
              "Year                                          0.052047   -0.124775   \n",
              "Temperature (C)                               0.736047    0.655034   \n",
              "pH                                            0.630247    0.581513   \n",
              "Conductivity (?Siemens/cm)                    1.000000    0.517452   \n",
              "BOD (mg/L)                                    0.517452    1.000000   \n",
              "Total coliform                                0.183180    0.192775   \n",
              "D.O. (mg/L)                                  -0.657547   -0.732868   \n",
              "\n",
              "                            Total coliform  D.O. (mg/L)  \n",
              "Year                             -0.034752     0.040632  \n",
              "Temperature (C)                   0.202834    -0.834528  \n",
              "pH                                0.162319    -0.638366  \n",
              "Conductivity (?Siemens/cm)        0.183180    -0.657547  \n",
              "BOD (mg/L)                        0.192775    -0.732868  \n",
              "Total coliform                    1.000000    -0.198014  \n",
              "D.O. (mg/L)                      -0.198014     1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27832620-a763-4b03-a1cf-f5628ceef30b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Year</th>\n",
              "      <th>Temperature (C)</th>\n",
              "      <th>pH</th>\n",
              "      <th>Conductivity (?Siemens/cm)</th>\n",
              "      <th>BOD (mg/L)</th>\n",
              "      <th>Total coliform</th>\n",
              "      <th>D.O. (mg/L)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Year</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.075839</td>\n",
              "      <td>-0.034884</td>\n",
              "      <td>0.052047</td>\n",
              "      <td>-0.124775</td>\n",
              "      <td>-0.034752</td>\n",
              "      <td>0.040632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Temperature (C)</th>\n",
              "      <td>0.075839</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.763918</td>\n",
              "      <td>0.736047</td>\n",
              "      <td>0.655034</td>\n",
              "      <td>0.202834</td>\n",
              "      <td>-0.834528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pH</th>\n",
              "      <td>-0.034884</td>\n",
              "      <td>0.763918</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.630247</td>\n",
              "      <td>0.581513</td>\n",
              "      <td>0.162319</td>\n",
              "      <td>-0.638366</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Conductivity (?Siemens/cm)</th>\n",
              "      <td>0.052047</td>\n",
              "      <td>0.736047</td>\n",
              "      <td>0.630247</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.517452</td>\n",
              "      <td>0.183180</td>\n",
              "      <td>-0.657547</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>BOD (mg/L)</th>\n",
              "      <td>-0.124775</td>\n",
              "      <td>0.655034</td>\n",
              "      <td>0.581513</td>\n",
              "      <td>0.517452</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.192775</td>\n",
              "      <td>-0.732868</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Total coliform</th>\n",
              "      <td>-0.034752</td>\n",
              "      <td>0.202834</td>\n",
              "      <td>0.162319</td>\n",
              "      <td>0.183180</td>\n",
              "      <td>0.192775</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-0.198014</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>D.O. (mg/L)</th>\n",
              "      <td>0.040632</td>\n",
              "      <td>-0.834528</td>\n",
              "      <td>-0.638366</td>\n",
              "      <td>-0.657547</td>\n",
              "      <td>-0.732868</td>\n",
              "      <td>-0.198014</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27832620-a763-4b03-a1cf-f5628ceef30b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27832620-a763-4b03-a1cf-f5628ceef30b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27832620-a763-4b03-a1cf-f5628ceef30b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-cc24a9e4-da73-4985-b0de-57c9aa7e3642\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc24a9e4-da73-4985-b0de-57c9aa7e3642')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-cc24a9e4-da73-4985-b0de-57c9aa7e3642 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 7,\n  \"fields\": [\n    {\n      \"column\": \"Year\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.38569203065865953,\n        \"min\": -0.12477503833844111,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          1.0,\n          0.0758390152081481,\n          -0.03475233984409303\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature (C)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6235192737608564,\n        \"min\": -0.8345284278589825,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.0758390152081481,\n          1.0,\n          0.2028343431256159\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pH\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5606784144420456,\n        \"min\": -0.638366428277522,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.034884217919455625,\n          0.7639176683159244,\n          0.16231878429794278\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Conductivity (?Siemens/cm)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5492188212777127,\n        \"min\": -0.6575470847462985,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.05204725084526611,\n          0.7360466412260294,\n          0.18317975073646398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BOD (mg/L)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5775401573225176,\n        \"min\": -0.7328684668407788,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.12477503833844111,\n          0.6550343907722262,\n          0.19277511691965513\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Total coliform\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3771848348318264,\n        \"min\": -0.19801449597140955,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          -0.03475233984409303,\n          0.2028343431256159,\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"D.O. (mg/L)\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6494818659840111,\n        \"min\": -0.8345284278589825,\n        \"max\": 1.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          0.04063195768266815,\n          -0.8345284278589825,\n          -0.19801449597140955\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "#correlation\n",
        "df.corr(method='pearson')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGkviHPwCcs_"
      },
      "outputs": [],
      "source": [
        "# Create train test split\n",
        "X_train = row[row['Year'].isin([2013,2014,2015,2016,2017,2018])][['Temperature (C)','pH','Conductivity (?Siemens/cm)','BOD (mg/L)']]\n",
        "X_val = row[row['Year'].isin([2019])][['Temperature (C)','pH','Conductivity (?Siemens/cm)','BOD (mg/L)']]\n",
        "X_test = row[row['Year']==2020][['Temperature (C)','pH','Conductivity (?Siemens/cm)','BOD (mg/L)']]\n",
        "\n",
        "y_train = row[row['Year'].isin([2013,2014,2015,2016,2017,2018])]['D.O. (mg/L)']\n",
        "y_val = row[row['Year'].isin([2019])]['D.O. (mg/L)']\n",
        "y_test = row[row['Year']==2020]['D.O. (mg/L)']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTIVARIATE LINEAR REGRESSION"
      ],
      "metadata": {
        "id": "sj-Wc5bfm2mJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LINEAR REGRESSION\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = y_train   # no Scaling\n",
        "y_val_scaled = y_val     # no scaling\n",
        "y_test_scaled = y_test     # no scaling\n",
        "\n",
        "# Linear Regression Model\n",
        "LR_model = LinearRegression()\n",
        "LR_model.fit(X_train_scaled, y_train_scaled)\n",
        "# Predictions on Train and Test Sets\n",
        "LR_train_pred = LR_model.predict(X_train_scaled)\n",
        "LR_val_pred=LR_model.predict(X_val_scaled)\n",
        "LR_test_pred = LR_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation Metrics\n",
        "train_mse = mean_squared_error(y_train, LR_train_pred)\n",
        "train_r2 = r2_score(y_train, LR_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "\n",
        "val_r2 = r2_score(y_val, LR_val_pred)\n",
        "\n",
        "# Print Evaluation Metrics for Training data set\n",
        "mean_observed_train = np.mean(y_train)\n",
        "train_index_of_agreement = 1 - (np.sum((y_train - LR_train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(LR_train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "print('Training Index of Agreement:', train_index_of_agreement)\n",
        "print('Training MSE:', train_mse)\n",
        "print('Training R^2:', train_r2)\n",
        "print('Training RMSE:', train_rmse)\n",
        "\n",
        "# Print Evaluation Metrics for Validation data set\n",
        "print('\\nValidation R2 R^2:', val_r2)  #this parameter will be used to get the best paraper values"
      ],
      "metadata": {
        "id": "zHSLDj7ECUDW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "549ea63e-7eef-4671-aeb0-73b818410a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Index of Agreement: 0.9713055533931432\n",
            "Training MSE: 0.6762565933875616\n",
            "Training R^2: 0.8943195404816819\n",
            "Training RMSE: 0.822348219057816\n",
            "\n",
            "Validation R2 R^2: 0.7873912458116864\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#LINEAR REGRESSION\n",
        "# Print Evaluation Metrics for Test data set\n",
        "mean_observed_test = np.mean(y_test)\n",
        "test_index_of_agreement = 1 - (np.sum((y_test - LR_test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(LR_test_pred - mean_observed_test)) ** 2))\n",
        "test_mse = mean_squared_error(y_test, LR_test_pred)\n",
        "test_r2 = r2_score(y_test, LR_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "print('\\nTesting Index of Agreement:', test_index_of_agreement)\n",
        "print('Testing MSE:', test_mse)\n",
        "print('Testing R^2:', test_r2)\n",
        "print('Test RMSE:', test_rmse)"
      ],
      "metadata": {
        "id": "OB4gIRtQCVQ1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8277b0-a8a2-4afc-b251-8a7161a3e4c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing Index of Agreement: 0.919230640283465\n",
            "Testing MSE: 2.6346486545895758\n",
            "Testing R^2: 0.7425616937790346\n",
            "Test RMSE: 1.623160082859844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MULTIVARIATE POLYNOMIAL REGRESSION"
      ],
      "metadata": {
        "id": "DvbYIsASnFpo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#polynomial Regression\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = y_train   # no Scaling\n",
        "y_val_scaled = y_val       # no scaling\n",
        "y_test_scaled = y_test     # no scaling\n",
        "\n",
        "# Importing Polynomial Regression Model\n",
        "grid_degree = [1,2, 3, 4, 5, 6]\n",
        "alpha = [1,1e-1]\n",
        "train_r2 = 0\n",
        "best_r2_val = -float('inf')\n",
        "best_degree = None\n",
        "best_alpha = None\n",
        "\n",
        "for d in grid_degree:\n",
        "    for a in alpha:\n",
        "        pr_model = make_pipeline(PolynomialFeatures(degree=d), Ridge(alpha=a))\n",
        "        pr_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "        # Predictions on Train and Validation Sets\n",
        "        pr_train_pred = pr_model.predict(X_train_scaled)\n",
        "        pr_val_pred = pr_model.predict(X_val_scaled)\n",
        "\n",
        "        # Evaluation Metrics on Validation Set\n",
        "        val_r2 = r2_score(y_val, pr_val_pred)\n",
        "        print(\"Degree:\", d, \"| Alpha:\", a, \"| Validation R^2:\", val_r2)\n",
        "\n",
        "        # Check if this degree and alpha gives better R^2 on validation set\n",
        "        if val_r2 > best_r2_val:\n",
        "            best_r2_val = val_r2\n",
        "            best_degree = d\n",
        "            best_alpha = a\n",
        "\n",
        "# Train the final model using the best degree and alpha\n",
        "pr_model = make_pipeline(PolynomialFeatures(degree=best_degree), Ridge(alpha=best_alpha))\n",
        "pr_model.fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "# Predictions on Train and Test Sets\n",
        "pr_train_pred = pr_model.predict(X_train_scaled)\n",
        "pr_val_pred = pr_model.predict(X_val_scaled)\n",
        "pr_test_pred = pr_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluation Metrics for training set\n",
        "train_mse = mean_squared_error(y_train, pr_train_pred)\n",
        "train_r2 = r2_score(y_train, pr_train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "mean_observed_train = np.mean(y_train)\n",
        "train_index_of_agreement = 1 - (np.sum((y_train - pr_train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(pr_train_pred - mean_observed_train)) ** 2))\n",
        "# Print Evaluation Metrics on training data\n",
        "print('Best Degree:', best_degree)\n",
        "print('Best Alpha:', best_alpha)\n",
        "print('\\nTraining MSE:', train_mse)\n",
        "print('Training R^2:', train_r2)\n",
        "print('Training RMSE:', train_rmse)\n",
        "print('Training Index of Agreement:', train_index_of_agreement)\n",
        "\n",
        "#Evaluation metrics on validation data for r2 value\n",
        "val_r2 = r2_score(y_val, pr_val_pred)\n",
        "print('\\nValidation R^2:', val_r2)\n"
      ],
      "metadata": {
        "id": "3LXb_aYCC84b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dbb3a9e-2b54-4f79-9568-a48f1a65ee60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Degree: 1 | Alpha: 1 | Validation R^2: 0.8177584553647865\n",
            "Degree: 1 | Alpha: 0.1 | Validation R^2: 0.796745026529988\n",
            "Degree: 2 | Alpha: 1 | Validation R^2: 0.7791505254450948\n",
            "Degree: 2 | Alpha: 0.1 | Validation R^2: 0.7799674109613488\n",
            "Degree: 3 | Alpha: 1 | Validation R^2: 0.7522736447473941\n",
            "Degree: 3 | Alpha: 0.1 | Validation R^2: 0.8081443030142094\n",
            "Degree: 4 | Alpha: 1 | Validation R^2: 0.7521432936370467\n",
            "Degree: 4 | Alpha: 0.1 | Validation R^2: 0.8256084800279435\n",
            "Degree: 5 | Alpha: 1 | Validation R^2: 0.7659821923815815\n",
            "Degree: 5 | Alpha: 0.1 | Validation R^2: 0.8145856830630033\n",
            "Degree: 6 | Alpha: 1 | Validation R^2: 0.78021542463331\n",
            "Degree: 6 | Alpha: 0.1 | Validation R^2: 0.7669937422356108\n",
            "Best Degree: 4\n",
            "Best Alpha: 0.1\n",
            "\n",
            "Training MSE: 0.5580500519707595\n",
            "Training R^2: 0.9127919986242667\n",
            "Training RMSE: 0.7470274773867154\n",
            "Training Index of Agreement: 0.9764528061475917\n",
            "\n",
            "Validation R^2: 0.8256084800279435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Polynomial Regression\n",
        "#Evaluation on testing data\n",
        "test_mse = mean_squared_error(y_test, pr_test_pred)\n",
        "test_r2 = r2_score(y_test, pr_test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "mean_observed_test = np.mean(y_test)\n",
        "test_index_of_agreement = 1 - (np.sum((y_test - pr_test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(pr_test_pred - mean_observed_test)) ** 2))\n",
        "print('\\nTesting MSE:', test_mse)\n",
        "print('Testing R^2:', test_r2)\n",
        "print('Test RMSE:', test_rmse)\n",
        "print('Testing Index of Agreement:', test_index_of_agreement)\n"
      ],
      "metadata": {
        "id": "HPATO6d-Di7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e63a684-7800-43f8-9bb6-256daac2c174"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Testing MSE: 3.0013933976593763\n",
            "Testing R^2: 0.7067261202930357\n",
            "Test RMSE: 1.7324530001299823\n",
            "Testing Index of Agreement: 0.9046812475952235\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RECURRENT NEURAL NETWORK"
      ],
      "metadata": {
        "id": "s6cc1i-VnNh2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Simple RNN\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "# Reshape data for Simple RNN\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_val_reshaped = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Initialize variables to store best h and average validation R^2 value\n",
        "best_h = None\n",
        "best_batch_size = None\n",
        "best_avg_val_r2 = -float('inf')\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store metrics for each iteration\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Batch sizes to try\n",
        "batch_sizes = [16, 32]\n",
        "h_values=[50,100,150,200,220]\n",
        "# Iterate through each value of batch size\n",
        "for batch_size in batch_sizes:\n",
        "    # Iterate through each value of h\n",
        "    for h in h_values:\n",
        "        # Lists to store validation R^2 values for each iteration\n",
        "        val_r2_values = []\n",
        "\n",
        "        # Perform multiple iterations for each h value and batch size\n",
        "        for _ in range(num_iterations):\n",
        "            # Model building and training with Simple RNN\n",
        "            Rnn_model = Sequential()\n",
        "            Rnn_model.add(SimpleRNN(h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "            Rnn_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "            Rnn_model.add(Dense(1))\n",
        "            Rnn_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "            # Early stopping to prevent overfitting\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            # Fit the model\n",
        "            Rnn_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "            # Predictions on training set and validation set\n",
        "            rnn_train_pred = Rnn_model.predict(X_train_reshaped).ravel()\n",
        "            train_pred=scaler_y.inverse_transform(rnn_train_pred.reshape(-1,1)).ravel()\n",
        "            rnn_val_pred = Rnn_model.predict(X_val_reshaped).ravel()\n",
        "            val_pred = scaler_y.inverse_transform(rnn_val_pred.reshape(-1,1)).ravel()\n",
        "\n",
        "            # Evaluation metrics on validation set\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            val_r2_values.append(val_r2)\n",
        "\n",
        "        # Calculate average validation R^2 for this h value and batch size\n",
        "        avg_val_r2 = np.mean(val_r2_values)\n",
        "\n",
        "        # Print average validation R^2 for this h value and batch size\n",
        "        print(\"Batch size:\", batch_size, \"| Node:\", h, \"| Average Validation R^2:\", avg_val_r2)\n",
        "\n",
        "        # Check if this h value and batch size combination gives a better average validation R^2\n",
        "        if avg_val_r2 > best_avg_val_r2:\n",
        "            best_avg_val_r2 = avg_val_r2\n",
        "            best_h = h\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "# Print the best h value and batch size\n",
        "print(\"Best h value:\", best_h)\n",
        "print(\"Best batch size:\", best_batch_size)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "  # Train the final model using the best h value\n",
        "  Rnn_model = Sequential()\n",
        "  Rnn_model.add(SimpleRNN(best_h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "  Rnn_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "  Rnn_model.add(Dense(1))\n",
        "  Rnn_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "  # Early stopping to prevent overfitting\n",
        "  early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "  # Fit the model on entire training data\n",
        "  Rnn_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=best_batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "  # Predictions on train and test\n",
        "  rnn_train_pred = Rnn_model.predict(X_train_reshaped).ravel()\n",
        "  rnn_test_pred= Rnn_model.predict(X_test_reshaped).ravel()\n",
        "  #inverse transformation\n",
        "  train_pred=scaler_y.inverse_transform(rnn_train_pred.reshape(-1,1)).ravel()\n",
        "  test_pred=scaler_y.inverse_transform(rnn_test_pred.reshape(-1,1)).ravel()\n",
        "\n",
        "  # Evaluation metrics\n",
        "  train_mse = mean_squared_error(y_train, train_pred)\n",
        "  train_r2 = r2_score(y_train, train_pred)\n",
        "  train_rmse = np.sqrt(train_mse)\n",
        "  test_mse = mean_squared_error(y_test, test_pred)\n",
        "  test_r2 = r2_score(y_test, test_pred)\n",
        "  test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "  # Calculate Index of Agreement for training set\n",
        "  mean_observed_train = np.mean(y_train)\n",
        "  train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "  # Calculate Index of Agreement for testing set\n",
        "  mean_observed_test = np.mean(y_test)\n",
        "  test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred- mean_observed_test)) ** 2))\n",
        "\n",
        "  # Append results to lists\n",
        "  train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "  test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "  train_mse_list.append(train_mse)\n",
        "  train_r2_list.append(train_r2)\n",
        "  train_rmse_list.append(train_rmse)\n",
        "  test_mse_list.append(test_mse)\n",
        "  test_r2_list.append(test_r2)\n",
        "  test_rmse_list.append(test_rmse)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSIyvRrH1jOd",
        "outputId": "ced5447d-70cc-4448-90fd-0941d32875d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Node : 50 | Validation R^2: 0.7652361964413564\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Node : 100 | Validation R^2: 0.7853865460237048\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Node : 150 | Validation R^2: 0.767942978190129\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Node : 200 | Validation R^2: 0.7720602690761549\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Node : 222 | Validation R^2: 0.7617774169399544\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 44ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Values for simple RNN\n",
        "# Evaluation metrics for training set\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "\n",
        "print(\"Average Train Index of Agreement:\", avg_train_index_of_agreement)\n",
        "print(\"Average Train MSE:\", avg_train_mse)\n",
        "print(\"Average Train R^2:\", avg_train_r2)\n",
        "print(\"Average Train RMSE:\", avg_train_rmse)\n",
        "\n",
        "val_r2 = r2_score(y_val, val_pred)\n",
        "print('\\nValidation R^2:', val_r2)\n",
        "\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "\n",
        "\n",
        "print(\"\\nAverage Test Index of Agreement:\", avg_test_index_of_agreement)\n",
        "print(\"Average Test MSE:\", avg_test_mse)\n",
        "print(\"Average Test R^2:\", avg_test_r2)\n",
        "print(\"Average Test RMSE:\", avg_test_rmse)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ij6BHFbR_pz7",
        "outputId": "9f14febd-6eca-4ae9-a466-539cb342cb3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.7312223728864049\n",
            "Average Training R^2: 0.8857298884294595\n",
            "Average Training RMSE: 0.8549669153349667\n",
            "Average Training Index of Agreement: 0.969790385280532\n",
            "\n",
            "Best h value based on R^2: 100\n",
            "Validation R^2 with best h: 0.7853865460237048\n",
            "\n",
            "Validation R^2: 0.7617774169399544\n",
            "\n",
            "Average Testing MSE: 2.2785315630699676\n",
            "Average Testing R^2: 0.7773588120579522\n",
            "Average Test RMSE: 1.5068335216125592\n",
            "Average Testing Index of Agreement: 0.9325352026931609\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "LSTM+RNN"
      ],
      "metadata": {
        "id": "lHX01MXinTTp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#LONG SHORT TERM MEMORY(LSTM)+RNN\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, SimpleRNN, Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Reshape data for LSTM+RNN\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_val_reshaped = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Initialize variables to store best h and average validation R^2 value\n",
        "best_h = None\n",
        "best_batch_size = None\n",
        "best_avg_val_r2 = -float('inf')\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store metrics for each iteration\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Batch sizes to try\n",
        "batch_sizes = [16, 32]\n",
        "h_values = [50, 100, 150, 200, 220]\n",
        "\n",
        "# Iterate through each value of batch size\n",
        "for batch_size in batch_sizes:\n",
        "    # Iterate through each value of h\n",
        "    for h in h_values:\n",
        "        # Lists to store validation R^2 values for each iteration\n",
        "        val_r2_values = []\n",
        "\n",
        "        # Perform multiple iterations for each h value and batch size\n",
        "        for _ in range(num_iterations):\n",
        "            # Model building and training with LSTM+RNN\n",
        "            lstm_rnn_model = Sequential()\n",
        "            lstm_rnn_model.add(LSTM(h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "            lstm_rnn_model.add(Dropout(0.1))  # Adding dropout for regularization\n",
        "            lstm_rnn_model.add(SimpleRNN(200))\n",
        "            lstm_rnn_model.add(Dropout(0.1))  # Adding dropout for regularization\n",
        "            lstm_rnn_model.add(Dense(1))\n",
        "            lstm_rnn_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "            # Early stopping to prevent overfitting\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            # Fit the model\n",
        "            lstm_rnn_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "            # Predictions on training set and validation set\n",
        "            lstm_rnn_train_pred = lstm_rnn_model.predict(X_train_reshaped).ravel()\n",
        "            train_pred = scaler_y.inverse_transform(lstm_rnn_train_pred.reshape(-1, 1)).ravel()\n",
        "            lstm_rnn_val_pred = lstm_rnn_model.predict(X_val_reshaped).ravel()\n",
        "            val_pred = scaler_y.inverse_transform(lstm_rnn_val_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "            # Evaluation metrics on validation set\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            val_r2_values.append(val_r2)\n",
        "\n",
        "        # Calculate average validation R^2 for this h value and batch size\n",
        "        avg_val_r2 = np.mean(val_r2_values)\n",
        "\n",
        "        # Print average validation R^2 for this h value and batch size\n",
        "        print(\"Batch size:\", batch_size, \"| Node:\", h, \"| Average Validation R^2:\", avg_val_r2)\n",
        "\n",
        "        # Check if this h value and batch size combination gives a better average validation R^2\n",
        "        if avg_val_r2 > best_avg_val_r2:\n",
        "            best_avg_val_r2 = avg_val_r2\n",
        "            best_h = h\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "# Print the best h value and batch size\n",
        "print(\"Best h value:\", best_h)\n",
        "print(\"Best batch size:\", best_batch_size)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Train the final model using the best h value\n",
        "    lstm_rnn_model = Sequential()\n",
        "    lstm_rnn_model.add(LSTM(best_h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "    lstm_rnn_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "    lstm_rnn_model.add(SimpleRNN(200))\n",
        "    lstm_rnn_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "    lstm_rnn_model.add(Dense(1))\n",
        "    lstm_rnn_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Fit the model on entire training data\n",
        "    lstm_rnn_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=best_batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Predictions on train and test\n",
        "    lstm_rnn_train_pred = lstm_rnn_model.predict(X_train_reshaped).ravel()\n",
        "    lstm_rnn_test_pred = lstm_rnn_model.predict(X_test_reshaped).ravel()\n",
        "\n",
        "    # Inverse transformation\n",
        "    train_pred = scaler_y.inverse_transform(lstm_rnn_train_pred.reshape(-1, 1)).ravel()\n",
        "    test_pred = scaler_y.inverse_transform(lstm_rnn_test_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Evaluation metrics\n",
        "    train_mse = mean_squared_error(y_train, train_pred)\n",
        "    train_r2 = r2_score(y_train, train_pred)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    test_r2 = r2_score(y_test, test_pred)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    # Calculate Index of Agreement for training set\n",
        "    mean_observed_train = np.mean(y_train)\n",
        "    train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "    # Calculate Index of Agreement for testing set\n",
        "    mean_observed_test = np.mean(y_test)\n",
        "    test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred - mean_observed_test)) ** 2))\n",
        "\n",
        "    # Append results to lists\n",
        "    train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "    test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "    train_mse_list.append(train_mse)\n",
        "    train_r2_list.append(train_r2)\n",
        "    train_rmse_list.append(train_rmse)\n",
        "    test_mse_list.append(test_mse)\n",
        "    test_r2_list.append(test_r2)\n",
        "    test_rmse_list.append(test_rmse)\n",
        "\n"
      ],
      "metadata": {
        "id": "F9NAAhYHfOzb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab2d4c9b-cdfd-4319-d380-c53b2ff5e5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c58016a3400> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c5803cbb880> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Batch size: 16 | Node: 50 | Average Validation R^2: 0.6749501931244443\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Batch size: 16 | Node: 100 | Average Validation R^2: 0.6819619553837236\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 1s 13ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Batch size: 16 | Node: 150 | Average Validation R^2: 0.6649356411332503\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Batch size: 16 | Node: 200 | Average Validation R^2: 0.6955479804232091\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 14ms/step\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "2/2 [==============================] - 2s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Batch size: 16 | Node: 220 | Average Validation R^2: 0.6863164858376695\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Batch size: 32 | Node: 50 | Average Validation R^2: 0.6493255909720466\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Batch size: 32 | Node: 100 | Average Validation R^2: 0.688112329400945\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Batch size: 32 | Node: 150 | Average Validation R^2: 0.6684373571682115\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 13ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 1s 10ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Batch size: 32 | Node: 200 | Average Validation R^2: 0.6823052055009045\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Batch size: 32 | Node: 220 | Average Validation R^2: 0.6831546323750165\n",
            "Best h value: 200\n",
            "Best batch size: 16\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "2/2 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 9ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "2/2 [==============================] - 1s 12ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "2/2 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Values for rnn+lstm\n",
        "# Evaluation metrics for training set\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "\n",
        "print('Average Training MSE:', avg_train_mse)\n",
        "print('Average Training R^2:', avg_train_r2)\n",
        "print('Average Training RMSE:', avg_train_rmse)\n",
        "print('Average Training Index of Agreement:', avg_train_index_of_agreement)\n",
        "\n",
        "val_r2=r2_score(y_val,val_pred)\n",
        "print('\\n Validation value of r2 score:',val_r2)\n",
        "\n",
        "# Evaluation metrics for testing set\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "print('\\nAverage Testing MSE:', avg_test_mse)\n",
        "print('Average Testing R^2:', avg_test_r2)\n",
        "print('Average Test RMSE:', avg_test_rmse)\n",
        "print('Average Testing Index of Agreement:', avg_test_index_of_agreement)\n"
      ],
      "metadata": {
        "id": "Memzs-MsfTSc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5675490a-f646-48f4-db7e-0feca00993a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.6151248759763346\n",
            "Average Training R^2: 0.7813944573900938\n",
            "Average Training RMSE: 0.7836570302432693\n",
            "Average Training Index of Agreement: 0.9365315966945532\n",
            "\n",
            " Validation value of r2 score: 0.6787278154120029\n",
            "\n",
            "Average Testing MSE: 2.270200485659189\n",
            "Average Testing R^2: 0.6414491620350008\n",
            "Average Test RMSE: 1.5046939237061263\n",
            "Average Testing Index of Agreement: 0.8449499971054264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLPNN"
      ],
      "metadata": {
        "id": "eoMXWo6yKsg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#MLPNN\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "X_train_scaled = scaler_X.fit_transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)  # Scaling validation set\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "y_train_scaled = y_train   # no Scaling\n",
        "y_val_scaled = y_val       # no scaling\n",
        "y_test_scaled = y_test     # no scaling\n",
        "\n",
        "# List of hidden layer configurations to try\n",
        "hidden_layer_configurations = [(100, 50), (100, 75),(125, 50), (125, 75), (125, 100),\n",
        "                                (150, 50), (150, 75), (150, 100), (150, 125),\n",
        "                                (175, 50), (175, 75), (175, 100), (175, 125),\n",
        "                                (200, 50), (200, 75), (200, 100), (200, 125)]\n",
        "\n",
        "# Initialize lists to store results\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Initialize variables to store best configuration and its corresponding performance\n",
        "best_config = None\n",
        "best_val_r2 = -float('inf')\n",
        "\n",
        "# Iterate over each hidden layer configuration\n",
        "for h in hidden_layer_configurations:\n",
        "  #  importing the Model  multilayer perceptron neural network\n",
        "  mlp_model = MLPRegressor(random_state=42, hidden_layer_sizes=h, max_iter=2000).fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "  # Predictions on training data and validation data\n",
        "  mlp_train_pred = mlp_model.predict(X_train_scaled)\n",
        "  mlp_val_pred = mlp_model.predict(X_val_scaled)\n",
        "\n",
        "  # Evaluation metrics on validation set\n",
        "  val_r2 = r2_score(y_val, mlp_val_pred)\n",
        "  print(\"Nodes:\", h, \"| Validation R^2:\", val_r2)\n",
        "\n",
        "\n",
        "  # Check if this configuration performs better than the current best\n",
        "  if val_r2 > best_val_r2:\n",
        "      best_val_r2 = val_r2\n",
        "      best_config = h\n",
        "for i in range(20):\n",
        "  # Use the best configuration on the testing set\n",
        "  mlp_model = MLPRegressor(random_state=42, hidden_layer_sizes=best_config, max_iter=2000).fit(X_train_scaled, y_train_scaled)\n",
        "\n",
        "  # Predictions on training and testing data\n",
        "  mlp_train_pred = mlp_model.predict(X_train_scaled)\n",
        "  mlp_test_pred = mlp_model.predict(X_test_scaled)\n",
        "\n",
        "  # Finding the METRICS of the MLPNN model on testing set\n",
        "  train_mse = mean_squared_error(y_train, mlp_train_pred)\n",
        "  train_r2 = r2_score(y_train, mlp_train_pred)\n",
        "  train_rmse = np.sqrt(train_mse)\n",
        "\n",
        "  test_mse = mean_squared_error(y_test, mlp_test_pred)\n",
        "  test_rmse = np.sqrt(test_mse)\n",
        "  test_r2 = r2_score(y_test, mlp_test_pred)\n",
        "  # Calculate Index of Agreement for training set\n",
        "  mean_observed_train = np.mean(y_train)\n",
        "  train_index_of_agreement = 1 - (np.sum((y_train - mlp_train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(mlp_train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "  # Calculate Index of Agreement for testing set\n",
        "  mean_observed_test = np.mean(y_test)\n",
        "  test_index_of_agreement = 1 - (np.sum((y_test - mlp_test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(mlp_test_pred - mean_observed_test)) ** 2))\n",
        "  # Append results to lists\n",
        "  train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "  test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "  train_mse_list.append(train_mse)\n",
        "  train_r2_list.append(train_r2)\n",
        "  train_rmse_list.append(train_rmse)\n",
        "  test_mse_list.append(test_mse)\n",
        "  test_r2_list.append(test_r2)\n",
        "  test_rmse_list.append(test_rmse)\n",
        "\n"
      ],
      "metadata": {
        "id": "GnVHMNwuGISR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2175319e-0cf2-48fe-b45b-bce3ff197159"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: (100, 50) | Validation R^2: 0.8261624084832422\n",
            "Nodes: (100, 75) | Validation R^2: 0.8114449306774596\n",
            "Nodes: (125, 50) | Validation R^2: 0.8638973005096444\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: (125, 75) | Validation R^2: 0.8720851176679506\n",
            "Nodes: (125, 100) | Validation R^2: 0.8438497258914053\n",
            "Nodes: (150, 50) | Validation R^2: 0.8727190438181436\n",
            "Nodes: (150, 75) | Validation R^2: 0.8595465646613102\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nodes: (150, 100) | Validation R^2: 0.875668990320954\n",
            "Nodes: (150, 125) | Validation R^2: 0.8374325163568487\n",
            "Nodes: (175, 50) | Validation R^2: 0.8395319280766367\n",
            "Nodes: (175, 75) | Validation R^2: 0.8414339233889707\n",
            "Nodes: (175, 100) | Validation R^2: 0.8407644298308558\n",
            "Nodes: (175, 125) | Validation R^2: 0.8450836442560121\n",
            "Nodes: (200, 50) | Validation R^2: 0.841700794899313\n",
            "Nodes: (200, 75) | Validation R^2: 0.8542970289614419\n",
            "Nodes: (200, 100) | Validation R^2: 0.8528208981004777\n",
            "Nodes: (200, 125) | Validation R^2: 0.8505013363191509\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (2000) reached and the optimization hasn't converged yet.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#MLPNN\n",
        "#MLPNN\n",
        "# Calculate  result ON TRAINING DATa\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "print('Average Training Index of Agreement:', avg_train_index_of_agreement)\n",
        "print('Average Training MSE:', avg_train_mse)\n",
        "print('Average Training R^2:', avg_train_r2)\n",
        "print('Average Training RMSE:', avg_train_rmse)\n",
        "\n",
        "print('Best hidden layer configuration:', best_config)\n",
        "\n",
        "val_r2 = r2_score(y_val, mlp_val_pred)\n",
        "print('\\nvalidation on r2:',val_r2)\n",
        "\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "print('\\nAverage Testing Index of Agreement:', avg_test_index_of_agreement)\n",
        "print('Average Testing MSE:', avg_test_mse)\n",
        "print('Average Testing R^2:', avg_test_r2)\n",
        "print('Average Testing RMSE:', avg_test_rmse)"
      ],
      "metadata": {
        "id": "2an7F9ziGsPy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2264313-f933-4f69-9b04-4094dbadf077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training Index of Agreement: 0.9873480156786515\n",
            "Average Training MSE: 0.3107801338291954\n",
            "Average Training R^2: 0.951433542129753\n",
            "Average Training RMSE: 0.5574765769332334\n",
            "Best hidden layer configuration: (150, 100)\n",
            "\n",
            "validation on r2: 0.8505013363191509\n",
            "\n",
            "Average Testing Index of Agreement: 0.849347411792639\n",
            "Average Testing MSE: 4.213418300859106\n",
            "Average Testing R^2: 0.5882960451352629\n",
            "Average Testing RMSE: 2.052661272801508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GATED RECURRENT NETWORK(GRU)"
      ],
      "metadata": {
        "id": "lWnGtyiAncj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Reshape data for GRU\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_val_reshaped = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Initialize variables to store best h and average validation R^2 value\n",
        "best_h = None\n",
        "best_batch_size = None\n",
        "best_avg_val_r2 = -float('inf')\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store metrics for each iteration\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Batch sizes to try\n",
        "batch_sizes = [16, 32]\n",
        "h_values = [50, 100, 150, 200, 220]\n",
        "\n",
        "# Iterate through each value of batch size\n",
        "for batch_size in batch_sizes:\n",
        "    # Iterate through each value of h\n",
        "    for h in h_values:\n",
        "        # Lists to store validation R^2 values for each iteration\n",
        "        val_r2_values = []\n",
        "\n",
        "        # Perform multiple iterations for each h value and batch size\n",
        "        for _ in range(num_iterations):\n",
        "            # Model building and training with GRU\n",
        "            gru_model = Sequential()\n",
        "            gru_model.add(GRU(h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "            gru_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "            gru_model.add(Dense(1))\n",
        "            gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "            # Early stopping to prevent overfitting\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            # Fit the model\n",
        "            gru_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "            # Predictions on testing set and validation set\n",
        "            gru_train_pred = gru_model.predict(X_train_reshaped).ravel()\n",
        "            train_pred = scaler_y.inverse_transform(gru_train_pred.reshape(-1, 1)).ravel()\n",
        "            gru_val_pred = gru_model.predict(X_val_reshaped).ravel()\n",
        "            val_pred = scaler_y.inverse_transform(gru_val_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "            # Evaluation metrics on validation set\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            val_r2_values.append(val_r2)\n",
        "\n",
        "        # Calculate average validation R^2 for this h value and batch size\n",
        "        avg_val_r2 = np.mean(val_r2_values)\n",
        "\n",
        "        # Print average validation R^2 for this h value and batch size\n",
        "        print(\"Batch size:\", batch_size, \"| Node:\", h, \"| Average Validation R^2:\", avg_val_r2)\n",
        "\n",
        "        # Check if this h value and batch size combination gives a better average validation R^2\n",
        "        if avg_val_r2 > best_avg_val_r2:\n",
        "            best_avg_val_r2 = avg_val_r2\n",
        "            best_h = h\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "# Print the best h value and batch size\n",
        "print(\"Best h value:\", best_h)\n",
        "print(\"Best batch size:\", best_batch_size)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Train the final model using the best h value\n",
        "    gru_model = Sequential()\n",
        "    gru_model.add(GRU(best_h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "    gru_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "    gru_model.add(Dense(1))\n",
        "    gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Fit the model on entire training data\n",
        "    gru_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=best_batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Predictions on train and test\n",
        "    gru_train_pred = gru_model.predict(X_train_reshaped).ravel()\n",
        "    gru_test_pred = gru_model.predict(X_test_reshaped).ravel()\n",
        "\n",
        "    # Inverse transformation\n",
        "    train_pred = scaler_y.inverse_transform(gru_train_pred.reshape(-1, 1)).ravel()\n",
        "    test_pred = scaler_y.inverse_transform(gru_test_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Evaluation metrics\n",
        "    train_mse = mean_squared_error(y_train, train_pred)\n",
        "    train_r2 = r2_score(y_train, train_pred)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    test_r2 = r2_score(y_test, test_pred)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    # Calculate Index of Agreement for training set\n",
        "    mean_observed_train = np.mean(y_train)\n",
        "    train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "    # Calculate Index of Agreement for testing set\n",
        "    mean_observed_test = np.mean(y_test)\n",
        "    test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred - mean_observed_test)) ** 2))\n",
        "\n",
        "    # Append results to lists\n",
        "    train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "    test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "    train_mse_list.append(train_mse)\n",
        "    train_r2_list.append(train_r2)\n",
        "    train_rmse_list.append(train_rmse)\n",
        "    test_mse_list.append(test_mse)\n",
        "    test_r2_list.append(test_r2)\n",
        "    test_rmse_list.append(test_rmse)\n"
      ],
      "metadata": {
        "id": "ApjIPS9wQwQt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17585f40-0ecd-4c88-db67-c06776f2fc31"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 627ms/step\n",
            "1/1 [==============================] - 0s 372ms/step\n",
            "1/1 [==============================] - 0s 397ms/step\n",
            "1/1 [==============================] - 0s 404ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d2fea28e320> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 382ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7d2fe51fae60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 1s 556ms/step\n",
            "1/1 [==============================] - 0s 355ms/step\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "1/1 [==============================] - 0s 355ms/step\n",
            "1/1 [==============================] - 0s 383ms/step\n",
            "Batch size: 16 | Node: 50 | Average Validation R^2: 0.8086354707789019\n",
            "1/1 [==============================] - 0s 364ms/step\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "1/1 [==============================] - 0s 398ms/step\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "1/1 [==============================] - 0s 403ms/step\n",
            "1/1 [==============================] - 0s 367ms/step\n",
            "1/1 [==============================] - 1s 580ms/step\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "1/1 [==============================] - 0s 397ms/step\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "Batch size: 16 | Node: 100 | Average Validation R^2: 0.8106095815736533\n",
            "1/1 [==============================] - 1s 586ms/step\n",
            "1/1 [==============================] - 0s 452ms/step\n",
            "1/1 [==============================] - 1s 540ms/step\n",
            "1/1 [==============================] - 0s 405ms/step\n",
            "1/1 [==============================] - 0s 383ms/step\n",
            "1/1 [==============================] - 0s 377ms/step\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "1/1 [==============================] - 0s 347ms/step\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "1/1 [==============================] - 0s 492ms/step\n",
            "Batch size: 16 | Node: 150 | Average Validation R^2: 0.810559959070909\n",
            "1/1 [==============================] - 0s 394ms/step\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "1/1 [==============================] - 0s 375ms/step\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "1/1 [==============================] - 0s 395ms/step\n",
            "1/1 [==============================] - 0s 390ms/step\n",
            "1/1 [==============================] - 0s 418ms/step\n",
            "1/1 [==============================] - 1s 601ms/step\n",
            "1/1 [==============================] - 1s 669ms/step\n",
            "Batch size: 16 | Node: 200 | Average Validation R^2: 0.815699172176999\n",
            "1/1 [==============================] - 1s 574ms/step\n",
            "1/1 [==============================] - 0s 395ms/step\n",
            "1/1 [==============================] - 0s 480ms/step\n",
            "1/1 [==============================] - 0s 378ms/step\n",
            "1/1 [==============================] - 0s 400ms/step\n",
            "1/1 [==============================] - 0s 396ms/step\n",
            "1/1 [==============================] - 1s 551ms/step\n",
            "1/1 [==============================] - 0s 398ms/step\n",
            "1/1 [==============================] - 0s 359ms/step\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "Batch size: 16 | Node: 220 | Average Validation R^2: 0.8173428854260356\n",
            "1/1 [==============================] - 0s 400ms/step\n",
            "1/1 [==============================] - 1s 608ms/step\n",
            "1/1 [==============================] - 0s 360ms/step\n",
            "1/1 [==============================] - 0s 392ms/step\n",
            "1/1 [==============================] - 0s 384ms/step\n",
            "1/1 [==============================] - 0s 375ms/step\n",
            "1/1 [==============================] - 1s 719ms/step\n",
            "1/1 [==============================] - 0s 368ms/step\n",
            "1/1 [==============================] - 1s 713ms/step\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "Batch size: 32 | Node: 50 | Average Validation R^2: 0.8217780156543173\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 380ms/step\n",
            "1/1 [==============================] - 0s 386ms/step\n",
            "1/1 [==============================] - 0s 377ms/step\n",
            "1/1 [==============================] - 0s 399ms/step\n",
            "1/1 [==============================] - 1s 628ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "1/1 [==============================] - 0s 376ms/step\n",
            "1/1 [==============================] - 0s 385ms/step\n",
            "Batch size: 32 | Node: 100 | Average Validation R^2: 0.8193974431648563\n",
            "1/1 [==============================] - 1s 841ms/step\n",
            "1/1 [==============================] - 1s 548ms/step\n",
            "1/1 [==============================] - 0s 391ms/step\n",
            "1/1 [==============================] - 0s 406ms/step\n",
            "1/1 [==============================] - 1s 505ms/step\n",
            "1/1 [==============================] - 0s 379ms/step\n",
            "1/1 [==============================] - 0s 375ms/step\n",
            "1/1 [==============================] - 0s 374ms/step\n",
            "1/1 [==============================] - 0s 402ms/step\n",
            "1/1 [==============================] - 0s 374ms/step\n",
            "Batch size: 32 | Node: 150 | Average Validation R^2: 0.8196752600437144\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "1/1 [==============================] - 0s 413ms/step\n",
            "1/1 [==============================] - 0s 382ms/step\n",
            "1/1 [==============================] - 0s 394ms/step\n",
            "1/1 [==============================] - 0s 404ms/step\n",
            "1/1 [==============================] - 1s 535ms/step\n",
            "1/1 [==============================] - 0s 389ms/step\n",
            "1/1 [==============================] - 0s 395ms/step\n",
            "1/1 [==============================] - 0s 383ms/step\n",
            "1/1 [==============================] - 1s 523ms/step\n",
            "Batch size: 32 | Node: 200 | Average Validation R^2: 0.8194282544866182\n",
            "1/1 [==============================] - 0s 381ms/step\n",
            "1/1 [==============================] - 1s 703ms/step\n",
            "1/1 [==============================] - 1s 595ms/step\n",
            "1/1 [==============================] - 1s 596ms/step\n",
            "1/1 [==============================] - 1s 579ms/step\n",
            "1/1 [==============================] - 0s 408ms/step\n",
            "1/1 [==============================] - 0s 364ms/step\n",
            "1/1 [==============================] - 1s 647ms/step\n",
            "1/1 [==============================] - 1s 954ms/step\n",
            "1/1 [==============================] - 1s 1s/step\n",
            "Batch size: 32 | Node: 220 | Average Validation R^2: 0.8207152980762114\n",
            "Best h value: 50\n",
            "Best batch size: 32\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 4s 6ms/step\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3/3 [==============================] - 1s 11ms/step\n",
            "1/1 [==============================] - 0s 83ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 42ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#values for GRU MODEL\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "\n",
        "print('Average Training MSE:', avg_train_mse)\n",
        "print('Average Training R^2:', avg_train_r2)\n",
        "print('Average Training RMSE:', avg_train_rmse)\n",
        "print('Average Training Index of Agreement:', avg_train_index_of_agreement)\n",
        "\n",
        "val_r2=r2_score(y_val,val_pred)\n",
        "print('\\n Validation value of r2 score:',val_r2)\n",
        "\n",
        "# Evaluation metrics for testing set\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "print('\\nAverage Testing MSE:', avg_test_mse)\n",
        "print('Average Testing R^2:', avg_test_r2)\n",
        "print('Average Test RMSE:', avg_test_rmse)\n",
        "print('Average Testing Index of Agreement:', avg_test_index_of_agreement)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jye60pCgmrPF",
        "outputId": "7ab35433-2f49-49cd-d431-dc76bcbe2b6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.808750663044307\n",
            "Average Training R^2: 0.8736143313913918\n",
            "Average Training RMSE: 0.8984746267357944\n",
            "Average Training Index of Agreement: 0.966538057557132\n",
            "\n",
            " Validation value of r2 score: 0.8332176011039142\n",
            "\n",
            "Average Testing MSE: 2.0445241693171194\n",
            "Average Testing R^2: 0.8002242772447324\n",
            "Average Test RMSE: 1.4287625361732916\n",
            "Average Testing Index of Agreement: 0.9363426393451952\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1D-CNN"
      ],
      "metadata": {
        "id": "Q537mt3d4epV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1D-CNN\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Initialize variables to store the best filter size and R^2 value\n",
        "best_filter_size = None\n",
        "best_val_r2 = -float('inf')\n",
        "\n",
        "# List of filter sizes to iterate over\n",
        "filter_sizes = [8, 16, 32, 64, 128]\n",
        "# Number of iterations for final evaluation\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store performance metrics for each iteration\n",
        "train_mse_list = []\n",
        "train_rmse_list = []\n",
        "train_r2_list = []\n",
        "train_ia_list = []\n",
        "test_mse_list = []\n",
        "test_rmse_list = []\n",
        "test_r2_list = []\n",
        "test_ia_list = []\n",
        "# Iterate over each filter size\n",
        "for filter_size in filter_sizes:\n",
        "    # Model definition\n",
        "    cnn_model = Sequential([\n",
        "        Conv1D(filters=filter_size, kernel_size=1, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
        "        Flatten(),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    cnn_model.compile(optimizer='adam', loss='mse')\n",
        "    # Fitting the model\n",
        "    cnn_model.fit(X_train_scaled[..., np.newaxis], y_train_scaled, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # predictions on training set and validation set\n",
        "    val_pred = cnn_model.predict(X_val_scaled[..., np.newaxis])\n",
        "    val_pred_inv = scaler_y.inverse_transform(val_pred).ravel()\n",
        "\n",
        "    # Calculate R^2 score\n",
        "    val_r2 = r2_score(y_val, val_pred_inv)\n",
        "    print(\"filter :\" ,filter_size,\"| Validation R^2:\", val_r2)\n",
        "\n",
        "    # Check if this filter size gives better R^2\n",
        "    if val_r2 > best_val_r2:\n",
        "        best_val_r2 = val_r2\n",
        "        best_filter_size = filter_size\n",
        "\n",
        "# Perform iterations\n",
        "for iteration in range(num_iterations):\n",
        "    # Model definition using the best filter size\n",
        "    cnn_model = Sequential([\n",
        "        Conv1D(filters=best_filter_size, kernel_size=1, activation='relu', input_shape=(X_train_scaled.shape[1], 1)),\n",
        "        Flatten(),\n",
        "        Dense(100, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    cnn_model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "    # Fit the final model\n",
        "    cnn_model.fit(X_train_scaled[..., np.newaxis], y_train_scaled, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "    # predictions on training and testing set\n",
        "    train_pred = cnn_model.predict(X_train_scaled[..., np.newaxis])\n",
        "    train_pred_inv = scaler_y.inverse_transform(train_pred).ravel()\n",
        "    test_pred = cnn_model.predict(X_test_scaled[..., np.newaxis])\n",
        "    test_pred_inv = scaler_y.inverse_transform(test_pred).ravel()\n",
        "\n",
        "    # Evaluate performance on testing set\n",
        "    test_mse = mean_squared_error(y_test, test_pred_inv)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "    test_r2 = r2_score(y_test, test_pred_inv)\n",
        "\n",
        "    # Evaluate performance on training set\n",
        "    train_mse = mean_squared_error(y_train, train_pred_inv)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    train_r2 = r2_score(y_train, train_pred_inv)\n",
        "    # Calculate Index of Agreement for training set\n",
        "    mean_observed_train = np.mean(y_train)\n",
        "    train_ia = 1 - (np.sum((y_train - train_pred_inv) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred_inv - mean_observed_train)) ** 2))\n",
        "\n",
        "    # Calculate Index of Agreement for testing set\n",
        "    mean_observed_test = np.mean(y_test)\n",
        "    test_ia = 1 - (np.sum((y_test - test_pred_inv) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred_inv - mean_observed_test)) ** 2))\n",
        "\n",
        "    # Append metrics to lists\n",
        "    train_mse_list.append(train_mse)\n",
        "    train_rmse_list.append(train_rmse)\n",
        "    train_r2_list.append(train_r2)\n",
        "    train_ia_list.append(train_ia)\n",
        "    test_mse_list.append(test_mse)\n",
        "    test_rmse_list.append(test_rmse)\n",
        "    test_r2_list.append(test_r2)\n",
        "    test_ia_list.append(test_ia)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFrdpNv84cpI",
        "outputId": "277c3eba-f2b8-455b-9278-a9e5d0094111"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step\n",
            "filter : 8 | Validation R^2: 0.798932023877702\n",
            "1/1 [==============================] - 0s 118ms/step\n",
            "filter : 16 | Validation R^2: 0.7767982277320646\n",
            "1/1 [==============================] - 0s 100ms/step\n",
            "filter : 32 | Validation R^2: 0.770169902490129\n",
            "1/1 [==============================] - 0s 258ms/step\n",
            "filter : 64 | Validation R^2: 0.8008917648743876\n",
            "1/1 [==============================] - 0s 326ms/step\n",
            "filter : 128 | Validation R^2: 0.7828542687369497\n",
            "3/3 [==============================] - 0s 10ms/step\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 0s 11ms/step\n",
            "1/1 [==============================] - 0s 84ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "1/1 [==============================] - 0s 112ms/step\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate average performance metrics\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_index_of_agreement = np.mean(train_ia_list)\n",
        "print(\"Average Training MSE:\", avg_train_mse)\n",
        "print(\"Average Training RMSE:\", avg_train_rmse)\n",
        "print(\"Average Training R^2:\", avg_train_r2)\n",
        "print(\"Average Training Index of agreement:\", avg_train_index_of_agreement)\n",
        "\n",
        "# Print the best R2 value on validation set\n",
        "print('\\nBest h value based on R^2:',best_filter_size )\n",
        "val_r2 = r2_score(y_val, val_pred)\n",
        "print('\\nValidation R^2:', best_val_r2)\n",
        "\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_index_of_agreement = np.mean(test_ia_list)\n",
        "print(\"\\nAverage Testing MSE:\", avg_test_mse)\n",
        "print(\"Average Testing RMSE:\", avg_test_rmse)\n",
        "print(\"Average Testing R^2:\", avg_test_r2)\n",
        "print(\"Average  Testing Index of agreement:\", avg_test_index_of_agreement)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NgGstGOT4kWF",
        "outputId": "6bce79b9-d0db-4c59-c82f-b74ced6a0f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.6650923081394863\n",
            "Average Training RMSE: 0.8139616819124456\n",
            "Average Training R^2: 0.8960642137414278\n",
            "Average Training Index of agreement: 0.972250152264948\n",
            "\n",
            "Best h value based on R^2: 64\n",
            "\n",
            "Validation R^2: 0.8008917648743876\n",
            "\n",
            "Average Testing MSE: 2.333188550565219\n",
            "Average Testing RMSE: 1.525077996728157\n",
            "Average Testing R^2: 0.772018137027372\n",
            "Average  Testing Index of agreement: 0.9277225518484904\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GRU+LSTM"
      ],
      "metadata": {
        "id": "IZzhQKVtpdzK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#GRU+LSTM\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Reshape data for GRU\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_val_reshaped = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Initialize variables to store best h and average validation R^2 value\n",
        "best_h = None\n",
        "best_batch_size = None\n",
        "best_avg_val_r2 = -float('inf')\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store metrics for each iteration\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Batch sizes to try\n",
        "batch_sizes = [16, 32]\n",
        "h_values = [50, 100, 150, 200, 220]\n",
        "\n",
        "# Iterate through each value of batch size\n",
        "for batch_size in batch_sizes:\n",
        "    # Iterate through each value of h\n",
        "    for h in h_values:\n",
        "        # Lists to store validation R^2 values for each iteration\n",
        "        val_r2_values = []\n",
        "\n",
        "        # Perform multiple iterations for each h value and batch size\n",
        "        for _ in range(num_iterations):\n",
        "            # Model building and training with GRU and LSTM\n",
        "            model = Sequential()\n",
        "            model.add(GRU(h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "            model.add(LSTM(50))\n",
        "            model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "            model.add(Dense(1))\n",
        "            model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "            # Early stopping to prevent overfitting\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            # Fit the model\n",
        "            model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "            # Predictions on training set and validation set\n",
        "            train_pred = model.predict(X_train_reshaped).ravel()\n",
        "            train_pred = scaler_y.inverse_transform(train_pred.reshape(-1, 1)).ravel()\n",
        "            val_pred = model.predict(X_val_reshaped).ravel()\n",
        "            val_pred = scaler_y.inverse_transform(val_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "            # Evaluation metrics on validation set\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            val_r2_values.append(val_r2)\n",
        "\n",
        "        # Calculate average validation R^2 for this h value and batch size\n",
        "        avg_val_r2 = np.mean(val_r2_values)\n",
        "\n",
        "        # Print average validation R^2 for this h value and batch size\n",
        "        print(\"Batch size:\", batch_size, \"| Node:\", h, \"| Average Validation R^2:\", avg_val_r2)\n",
        "\n",
        "        # Check if this h value and batch size combination gives a better average validation R^2\n",
        "        if avg_val_r2 > best_avg_val_r2:\n",
        "            best_avg_val_r2 = avg_val_r2\n",
        "            best_h = h\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "# Print the best h value and batch size\n",
        "print(\"Best h value:\", best_h)\n",
        "print(\"Best batch size:\", best_batch_size)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Train the final model using the best h value\n",
        "    model = Sequential()\n",
        "    model.add(GRU(best_h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]), return_sequences=True))\n",
        "    model.add(LSTM(best_h))\n",
        "    model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "    model.add(Dense(1))\n",
        "    model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Fit the model on entire training data\n",
        "    model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=best_batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Predictions on train and test\n",
        "    train_pred = model.predict(X_train_reshaped).ravel()\n",
        "    test_pred = model.predict(X_test_reshaped).ravel()\n",
        "\n",
        "    # Inverse transformation\n",
        "    train_pred = scaler_y.inverse_transform(train_pred.reshape(-1, 1)).ravel()\n",
        "    test_pred = scaler_y.inverse_transform(test_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Evaluation metrics\n",
        "    train_mse = mean_squared_error(y_train, train_pred)\n",
        "    train_r2 = r2_score(y_train, train_pred)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    test_r2 = r2_score(y_test, test_pred)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    # Calculate Index of Agreement for training set\n",
        "    mean_observed_train = np.mean(y_train)\n",
        "    train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "    # Calculate Index of Agreement for testing set\n",
        "    mean_observed_test = np.mean(y_test)\n",
        "    test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred - mean_observed_test)) ** 2))\n",
        "\n",
        "    # Append results to lists\n",
        "    train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "    test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "    train_mse_list.append(train_mse)\n",
        "    train_r2_list.append(train_r2)\n",
        "    train_rmse_list.append(train_rmse)\n",
        "    test_mse_list.append(test_mse)\n",
        "    test_r2_list.append(test_r2)\n",
        "    test_rmse_list.append(test_rmse)\n"
      ],
      "metadata": {
        "id": "dfrSd2zqpgPi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac4272ec-c422-495f-f40c-c1b483d630d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Nodes: 50 | Validation R^2: 0.8247948681199169\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Nodes: 100 | Validation R^2: 0.8142076284280759\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nodes: 150 | Validation R^2: 0.8286933398780651\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "Nodes: 200 | Validation R^2: 0.8572348145695804\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "Nodes: 222 | Validation R^2: 0.8347213766348854\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Values for  gru+lstm\n",
        "# Evaluation metrics for training set\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "\n",
        "print('Average Training MSE:', avg_train_mse)\n",
        "print('Average Training R^2:', avg_train_r2)\n",
        "print('Average Training RMSE:', avg_train_rmse)\n",
        "print('Average Training Index of Agreement:', avg_train_index_of_agreement)\n",
        "\n",
        "val_r2=r2_score(y_val,val_pred)\n",
        "print('\\n Validation value of r2 score:',val_r2)\n",
        "\n",
        "# Evaluation metrics for testing set\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "print('\\nAverage Testing MSE:', avg_test_mse)\n",
        "print('Average Testing R^2:', avg_test_r2)\n",
        "print('Average Test RMSE:', avg_test_rmse)\n",
        "print('Average Testing Index of Agreement:', avg_test_index_of_agreement)"
      ],
      "metadata": {
        "id": "qTNraN3zr2gP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e431f222-fbb2-4ee3-f70f-264c0ed98902"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.74349832630343\n",
            "Average Training R^2: 0.883811491757513\n",
            "Average Training RMSE: 0.8618302548578838\n",
            "Average Training Index of Agreement: 0.969282907507008\n",
            "\n",
            "Best h value based on R^2: 200\n",
            "\n",
            " Validation value of r2 score: 0.8347213766348854\n",
            "\n",
            "Average Testing MSE: 2.489555510227509\n",
            "Average Testing R^2: 0.7567391186374786\n",
            "Average Test RMSE: 1.5762477194893096\n",
            "Average Testing Index of Agreement: 0.9234599901305911\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RBFN"
      ],
      "metadata": {
        "id": "OXootrRgMDl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#RBFNN\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "y_val_scaled = scaler_y.transform(y_val.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Number of RBF centers\n",
        "n_centers = min(100, len(X_train_scaled))\n",
        "\n",
        "# Use KMeans to get the centers\n",
        "kmeans = KMeans(n_clusters=n_centers, random_state=42).fit(X_train_scaled)\n",
        "centers = kmeans.cluster_centers_\n",
        "\n",
        "# Calculate the widths\n",
        "distances = euclidean_distances(centers, [centers[0]])\n",
        "median_distance = np.median(distances)\n",
        "sigma = median_distance / np.sqrt(2 * np.log(2))\n",
        "\n",
        "# Initialize variables to store best alpha and corresponding performance\n",
        "best_alpha = None\n",
        "best_val_r2 = -float('inf')\n",
        "\n",
        "# Iterate over each alpha value\n",
        "for alpha in [1, 0.1, 0.01, 0.001]:\n",
        "    # Calculate RBF features\n",
        "    X_train_rbf = rbf_kernel(X_train_scaled, centers, gamma=1.0 / sigma)\n",
        "    X_val_rbf = rbf_kernel(X_val_scaled, centers, gamma=1.0 / sigma)\n",
        "\n",
        "    # Model the Radial Basis Function Network\n",
        "    rbf_pipeline = make_pipeline(Ridge(alpha=alpha, fit_intercept=False))\n",
        "    rbf_pipeline.fit(X_train_rbf, y_train_scaled)\n",
        "\n",
        "    # Prediction for validation dataset\n",
        "    rbfn_val_pred = rbf_pipeline.predict(X_val_rbf)\n",
        "\n",
        "    # Inverse transform the predictions to get them back to the original scale\n",
        "    val_pred = scaler_y.inverse_transform(rbfn_val_pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Finding the r^2 of the RBFN model\n",
        "    val_r2 = r2_score(y_val, val_pred)\n",
        "    print(\"Alpha Values:\", alpha, \"| Validation R^2:\", val_r2)\n",
        "\n",
        "    # Check if this alpha performs better than the current best\n",
        "    if val_r2 > best_val_r2:\n",
        "        best_val_r2 = val_r2\n",
        "        best_alpha = alpha\n",
        "\n",
        "# Use the best alpha value on the testing set\n",
        "X_test_rbf = rbf_kernel(X_test_scaled, centers, gamma=1.0 / sigma)\n",
        "rbf_pipeline = make_pipeline(Ridge(alpha=best_alpha, fit_intercept=False))\n",
        "rbf_pipeline.fit(X_train_rbf, y_train_scaled)\n",
        "rbfn_test_pred = rbf_pipeline.predict(X_test_rbf)\n",
        "# Use the best alpha value on the training set\n",
        "rbf_pipeline_train = make_pipeline(Ridge(alpha=best_alpha, fit_intercept=False))\n",
        "rbf_pipeline_train.fit(X_train_rbf, y_train_scaled)\n",
        "rbfn_train_pred = rbf_pipeline_train.predict(X_train_rbf)\n",
        "\n",
        "# Inverse transform the predictions to get them back to the original scale\n",
        "train_pred = scaler_y.inverse_transform(rbfn_train_pred.reshape(-1, 1)).flatten()\n",
        "test_pred = scaler_y.inverse_transform(rbfn_test_pred.reshape(-1, 1)).flatten()\n",
        "\n",
        "# Finding the mse of the RBFN model on testing set\n",
        "train_mse = mean_squared_error(y_train, train_pred)\n",
        "train_r2 = r2_score(y_train, train_pred)\n",
        "train_rmse = np.sqrt(train_mse)\n",
        "\n",
        "test_mse = mean_squared_error(y_test, test_pred)\n",
        "test_rmse = np.sqrt(test_mse)\n",
        "test_r2 = r2_score(y_test, test_pred)\n",
        "# Calculate Index of Agreement for training set\n",
        "mean_observed_train = np.mean(y_train)\n",
        "train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "# Calculate Index of Agreement for testing set\n",
        "mean_observed_test = np.mean(y_test)\n",
        "test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred - mean_observed_test)) ** 2))"
      ],
      "metadata": {
        "id": "UpW_QWgxCfIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f0752af-e2d5-467a-d95b-63e8e24e4397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alpha Values: 1 | Validation R^2: 0.7985711496487397\n",
            "Alpha Values: 0.1 | Validation R^2: 0.8036714215108244\n",
            "Alpha Values: 0.01 | Validation R^2: 0.8256003611417779\n",
            "Alpha Values: 0.001 | Validation R^2: 0.8411300109120768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RBFNN\n",
        "print('Training MSE:', train_mse)\n",
        "print('Training RMSE:', train_rmse)\n",
        "print('Training R^2:', train_r2)\n",
        "print('Training Index of Agreement:', train_index_of_agreement)\n",
        "\n",
        "print('\\nBest alpha value:', best_alpha)\n",
        "\n",
        "val_r2 = r2_score(y_val, val_pred)\n",
        "print('Validation r2 value:',val_r2)\n",
        "\n",
        "print('\\nTesting MSE:', test_mse)\n",
        "print('Testing RMSE:', test_rmse)\n",
        "print('Testing R^2:', test_r2)\n",
        "print('Testing Index of Agreement:', test_index_of_agreement)"
      ],
      "metadata": {
        "id": "8zZyikmtMK9G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d4f3b03-5090-40be-b5dc-f11cece1f56e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training MSE: 0.49929488588290505\n",
            "Training RMSE: 0.7066080143070167\n",
            "Training R^2: 0.9219738284385027\n",
            "Training Index of Agreement: 0.9792327073874852\n",
            "\n",
            "Best alpha value: 0.001\n",
            "Validation r2 value: 0.8411300109120768\n",
            "\n",
            "Testing MSE: 3.688059239244568\n",
            "Testing RMSE: 1.9204320449431602\n",
            "Testing R^2: 0.6396302322361809\n",
            "Testing Index of Agreement: 0.8788408762880459\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BI-DIRECTIONAL GRU"
      ],
      "metadata": {
        "id": "BOJyUpM7nju6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bi-directional gru\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Reshape data for Bidirectional GRU\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_val_reshaped = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Initialize variables to store best h and average validation R^2 value\n",
        "best_h = None\n",
        "best_batch_size = None\n",
        "best_avg_val_r2 = -float('inf')\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store metrics for each iteration\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Batch sizes to try\n",
        "batch_sizes = [16, 32]\n",
        "h_values = [50, 100, 150, 200, 220]\n",
        "\n",
        "# Iterate through each value of batch size\n",
        "for batch_size in batch_sizes:\n",
        "    # Iterate through each value of h\n",
        "    for h in h_values:\n",
        "        # Lists to store validation R^2 values for each iteration\n",
        "        val_r2_values = []\n",
        "\n",
        "        # Perform multiple iterations for each h value and batch size\n",
        "        for _ in range(num_iterations):\n",
        "            # Model building and training with Bidirectional GRU\n",
        "            bidirectional_gru_model = Sequential()\n",
        "            bidirectional_gru_model.add(Bidirectional(GRU(h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))))\n",
        "            bidirectional_gru_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "            bidirectional_gru_model.add(Dense(1))\n",
        "            bidirectional_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "            # Early stopping to prevent overfitting\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            # Fit the model\n",
        "            bidirectional_gru_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "            # Predictions on training set and validation set\n",
        "            bidirectional_gru_train_pred = bidirectional_gru_model.predict(X_train_reshaped).ravel()\n",
        "            train_pred = scaler_y.inverse_transform(bidirectional_gru_train_pred.reshape(-1, 1)).ravel()\n",
        "            bidirectional_gru_val_pred = bidirectional_gru_model.predict(X_val_reshaped).ravel()\n",
        "            val_pred = scaler_y.inverse_transform(bidirectional_gru_val_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "            # Evaluation metrics on validation set\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            val_r2_values.append(val_r2)\n",
        "\n",
        "        # Calculate average validation R^2 for this h value and batch size\n",
        "        avg_val_r2 = np.mean(val_r2_values)\n",
        "\n",
        "        # Print average validation R^2 for this h value and batch size\n",
        "        print(\"Batch size:\", batch_size, \"| Node:\", h, \"| Average Validation R^2:\", avg_val_r2)\n",
        "\n",
        "        # Check if this h value and batch size combination gives a better average validation R^2\n",
        "        if avg_val_r2 > best_avg_val_r2:\n",
        "            best_avg_val_r2 = avg_val_r2\n",
        "            best_h = h\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "# Print the best h value and batch size\n",
        "print(\"Best h value:\", best_h)\n",
        "print(\"Best batch size:\", best_batch_size)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Train the final model using the best h value\n",
        "    bidirectional_gru_model = Sequential()\n",
        "    bidirectional_gru_model.add(Bidirectional(GRU(best_h, input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2]))))\n",
        "    bidirectional_gru_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "    bidirectional_gru_model.add(Dense(1))\n",
        "    bidirectional_gru_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Fit the model on entire training data\n",
        "    bidirectional_gru_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=best_batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Predictions on train and test\n",
        "    bidirectional_gru_train_pred = bidirectional_gru_model.predict(X_train_reshaped).ravel()\n",
        "    bidirectional_gru_test_pred = bidirectional_gru_model.predict(X_test_reshaped).ravel()\n",
        "\n",
        "    # Inverse transformation\n",
        "    train_pred = scaler_y.inverse_transform(bidirectional_gru_train_pred.reshape(-1, 1)).ravel()\n",
        "    test_pred = scaler_y.inverse_transform(bidirectional_gru_test_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Evaluation metrics\n",
        "    train_mse = mean_squared_error(y_train, train_pred)\n",
        "    train_r2 = r2_score(y_train, train_pred)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    test_r2 = r2_score(y_test, test_pred)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    # Calculate Index of Agreement for training set\n",
        "    mean_observed_train = np.mean(y_train)\n",
        "    train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "    # Calculate Index of Agreement for testing set\n",
        "    mean_observed_test = np.mean(y_test)\n",
        "    test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred - mean_observed_test)) ** 2))\n",
        "\n",
        "    # Append results to lists\n",
        "    train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "    test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "    train_mse_list.append(train_mse)\n",
        "    train_r2_list.append(train_r2)\n",
        "    train_rmse_list.append(train_rmse)\n",
        "    test_mse_list.append(test_mse)\n",
        "    test_r2_list.append(test_r2)\n",
        "    test_rmse_list.append(test_rmse)\n",
        "\n"
      ],
      "metadata": {
        "id": "Q9zJG5j3SjAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97fcf8f8-d43e-4266-bb3d-fff7c8738cf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 33ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Batch size: 16 | Node: 50 | Average Validation R^2: 0.7971331688120366\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "Batch size: 16 | Node: 100 | Average Validation R^2: 0.7999207030256578\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Batch size: 16 | Node: 150 | Average Validation R^2: 0.8039886972744661\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Batch size: 16 | Node: 200 | Average Validation R^2: 0.8002473337706533\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 31ms/step\n",
            "Batch size: 16 | Node: 220 | Average Validation R^2: 0.8038289335758643\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3/3 [==============================] - 1s 4ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Batch size: 32 | Node: 50 | Average Validation R^2: 0.8104293296856865\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "Batch size: 32 | Node: 100 | Average Validation R^2: 0.8107475365725284\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "Batch size: 32 | Node: 150 | Average Validation R^2: 0.8151751558003084\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Batch size: 32 | Node: 200 | Average Validation R^2: 0.8135216691031616\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 8ms/step\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 7ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "Batch size: 32 | Node: 220 | Average Validation R^2: 0.8137388080358603\n",
            "Best h value: 150\n",
            "Best batch size: 32\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 6ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "3/3 [==============================] - 1s 5ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Values for Bi-directional gru\n",
        "# Evaluation metrics for training set\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "\n",
        "print('Average Training MSE:', avg_train_mse)\n",
        "print('Average Training R^2:', avg_train_r2)\n",
        "print('Average Training RMSE:', avg_train_rmse)\n",
        "print('Average Training Index of Agreement:', avg_train_index_of_agreement)\n",
        "\n",
        "val_r2=r2_score(y_val,val_pred)\n",
        "print('\\n Validation value of r2 score:',val_r2)\n",
        "\n",
        "# Evaluation metrics for testing set\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "print('\\nAverage Testing MSE:', avg_test_mse)\n",
        "print('Average Testing R^2:', avg_test_r2)\n",
        "print('Average Test RMSE:', avg_test_rmse)\n",
        "print('Average Testing Index of Agreement:', avg_test_index_of_agreement)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJVvCHVjxS93",
        "outputId": "73fae055-257c-4146-df63-fc744cc00a3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.7804097216892179\n",
            "Average Training R^2: 0.8780432474786778\n",
            "Average Training RMSE: 0.8811700521432868\n",
            "Average Training Index of Agreement: 0.9680261869496727\n",
            "\n",
            " Validation value of r2 score: 0.8099064426351502\n",
            "\n",
            "Average Testing MSE: 2.048476471907933\n",
            "Average Testing R^2: 0.7998380875784636\n",
            "Average Test RMSE: 1.42893123062987\n",
            "Average Testing Index of Agreement: 0.9376333297943091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BI-DIRECTIONAL GRU+LSTM"
      ],
      "metadata": {
        "id": "ZYtVIj0yoDiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Bi-directional GRU+LSTM\n",
        "# Normalize features and target variable using only training data\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_X.fit(X_train)\n",
        "X_train_scaled = scaler_X.transform(X_train)\n",
        "X_val_scaled = scaler_X.transform(X_val)\n",
        "X_test_scaled = scaler_X.transform(X_test)\n",
        "\n",
        "scaler_y = MinMaxScaler()\n",
        "scaler_y.fit(y_train.values.reshape(-1, 1))\n",
        "y_train_scaled = scaler_y.transform(y_train.values.reshape(-1, 1)).ravel()\n",
        "\n",
        "# Reshape data for GRU\n",
        "X_train_reshaped = X_train_scaled.reshape((X_train_scaled.shape[0], 1, X_train_scaled.shape[1]))\n",
        "X_val_reshaped = X_val_scaled.reshape((X_val_scaled.shape[0], 1, X_val_scaled.shape[1]))\n",
        "X_test_reshaped = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
        "\n",
        "# Initialize variables to store best h and average validation R^2 value\n",
        "best_h = None\n",
        "best_batch_size = None\n",
        "best_avg_val_r2 = -float('inf')\n",
        "\n",
        "# Number of iterations\n",
        "num_iterations = 10\n",
        "\n",
        "# Lists to store metrics for each iteration\n",
        "train_index_of_agreement_list = []\n",
        "test_index_of_agreement_list = []\n",
        "train_mse_list = []\n",
        "train_r2_list = []\n",
        "train_rmse_list = []\n",
        "test_mse_list = []\n",
        "test_r2_list = []\n",
        "test_rmse_list = []\n",
        "\n",
        "# Batch sizes to try\n",
        "batch_sizes = [16, 32]\n",
        "h_values = [50, 100, 150, 200, 220]\n",
        "\n",
        "# Iterate through each value of batch size\n",
        "for batch_size in batch_sizes:\n",
        "    # Iterate through each value of h\n",
        "    for h in h_values:\n",
        "        # Lists to store validation R^2 values for each iteration\n",
        "        val_r2_values = []\n",
        "\n",
        "        # Perform multiple iterations for each h value and batch size\n",
        "        for _ in range(num_iterations):\n",
        "            # Model building and training with bidirectional GRU and LSTM\n",
        "            bi_gru_lstm_model = Sequential()\n",
        "            bi_gru_lstm_model.add(Bidirectional(GRU(h, return_sequences=True), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "            bi_gru_lstm_model.add(Bidirectional(LSTM(50)))\n",
        "            bi_gru_lstm_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "            bi_gru_lstm_model.add(Dense(1))\n",
        "            bi_gru_lstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "            # Early stopping to prevent overfitting\n",
        "            early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "            # Fit the model\n",
        "            bi_gru_lstm_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "            # Predictions on training set and validation set\n",
        "            train_pred = bi_gru_lstm_model.predict(X_train_reshaped).ravel()\n",
        "            train_pred = scaler_y.inverse_transform(train_pred.reshape(-1, 1)).ravel()\n",
        "            val_pred = bi_gru_lstm_model.predict(X_val_reshaped).ravel()\n",
        "            val_pred = scaler_y.inverse_transform(val_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "            # Evaluation metrics on validation set\n",
        "            val_r2 = r2_score(y_val, val_pred)\n",
        "            val_r2_values.append(val_r2)\n",
        "\n",
        "        # Calculate average validation R^2 for this h value and batch size\n",
        "        avg_val_r2 = np.mean(val_r2_values)\n",
        "\n",
        "        # Print average validation R^2 for this h value and batch size\n",
        "        print(\"Batch size:\", batch_size, \"| Node:\", h, \"| Average Validation R^2:\", avg_val_r2)\n",
        "\n",
        "        # Check if this h value and batch size combination gives a better average validation R^2\n",
        "        if avg_val_r2 > best_avg_val_r2:\n",
        "            best_avg_val_r2 = avg_val_r2\n",
        "            best_h = h\n",
        "            best_batch_size = batch_size\n",
        "\n",
        "# Print the best h value and batch size\n",
        "print(\"Best h value:\", best_h)\n",
        "print(\"Best batch size:\", best_batch_size)\n",
        "\n",
        "for iteration in range(num_iterations):\n",
        "    # Train the final model using the best h value\n",
        "    bi_gru_lstm_model = Sequential()\n",
        "    bi_gru_lstm_model.add(Bidirectional(GRU(best_h, return_sequences=True), input_shape=(X_train_reshaped.shape[1], X_train_reshaped.shape[2])))\n",
        "    bi_gru_lstm_model.add(Bidirectional(LSTM(best_h)))\n",
        "    bi_gru_lstm_model.add(Dropout(0.1))  # Adding dropout with a rate of 0.1\n",
        "    bi_gru_lstm_model.add(Dense(1))\n",
        "    bi_gru_lstm_model.compile(optimizer=Adam(learning_rate=0.01), loss='mean_squared_error')\n",
        "\n",
        "    # Early stopping to prevent overfitting\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "\n",
        "    # Fit the model on entire training data\n",
        "    bi_gru_lstm_model.fit(X_train_reshaped, y_train_scaled, epochs=5000, batch_size=best_batch_size, validation_split=0.2, callbacks=[early_stopping], verbose=0)\n",
        "\n",
        "    # Predictions on train and test\n",
        "    train_pred = bi_gru_lstm_model.predict(X_train_reshaped).ravel()\n",
        "    test_pred = bi_gru_lstm_model.predict(X_test_reshaped).ravel()\n",
        "\n",
        "    # Inverse transformation\n",
        "    train_pred = scaler_y.inverse_transform(train_pred.reshape(-1, 1)).ravel()\n",
        "    test_pred = scaler_y.inverse_transform(test_pred.reshape(-1, 1)).ravel()\n",
        "\n",
        "    # Evaluation metrics\n",
        "    train_mse = mean_squared_error(y_train, train_pred)\n",
        "    train_r2 = r2_score(y_train, train_pred)\n",
        "    train_rmse = np.sqrt(train_mse)\n",
        "    test_mse = mean_squared_error(y_test, test_pred)\n",
        "    test_r2 = r2_score(y_test, test_pred)\n",
        "    test_rmse = np.sqrt(test_mse)\n",
        "\n",
        "    # Calculate Index of Agreement for training set\n",
        "    mean_observed_train = np.mean(y_train)\n",
        "    train_index_of_agreement = 1 - (np.sum((y_train - train_pred) ** 2) / np.sum((np.abs(y_train - mean_observed_train) + np.abs(train_pred - mean_observed_train)) ** 2))\n",
        "\n",
        "    # Calculate Index of Agreement for testing set\n",
        "    mean_observed_test = np.mean(y_test)\n",
        "    test_index_of_agreement = 1 - (np.sum((y_test - test_pred) ** 2) / np.sum((np.abs(y_test - mean_observed_test) + np.abs(test_pred - mean_observed_test)) ** 2))\n",
        "\n",
        "    # Append results to lists\n",
        "    train_index_of_agreement_list.append(train_index_of_agreement)\n",
        "    test_index_of_agreement_list.append(test_index_of_agreement)\n",
        "    train_mse_list.append(train_mse)\n",
        "    train_r2_list.append(train_r2)\n",
        "    train_rmse_list.append(train_rmse)\n",
        "    test_mse_list.append(test_mse)\n",
        "    test_r2_list.append(test_r2)\n",
        "    test_rmse_list.append(test_rmse)\n"
      ],
      "metadata": {
        "id": "-OXVb_UBoLXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3bd4a39-c955-4854-9294-9f2f8ca13d34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 2s 5ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Nodes: 50 | Validation R^2: 0.8177109327976265\n",
            "3/3 [==============================] - 2s 9ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "Nodes: 100 | Validation R^2: 0.8166394930890623\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Nodes: 150 | Validation R^2: 0.8272726382535656\n",
            "3/3 [==============================] - 2s 7ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "Nodes: 200 | Validation R^2: 0.8114616342641955\n",
            "3/3 [==============================] - 2s 7ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "Nodes: 222 | Validation R^2: 0.804239566490819\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 2s 8ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 2s 5ms/step\n",
            "1/1 [==============================] - 0s 22ms/step\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 23ms/step\n",
            "3/3 [==============================] - 2s 6ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "3/3 [==============================] - 2s 9ms/step\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "3/3 [==============================] - 2s 7ms/step\n",
            "1/1 [==============================] - 0s 25ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Values for Bi-directional gru+lstm\n",
        "# Evaluation metrics for training set\n",
        "avg_train_index_of_agreement = np.mean(train_index_of_agreement_list)\n",
        "avg_train_mse = np.mean(train_mse_list)\n",
        "avg_train_r2 = np.mean(train_r2_list)\n",
        "avg_train_rmse = np.mean(train_rmse_list)\n",
        "\n",
        "print('Average Training MSE:', avg_train_mse)\n",
        "print('Average Training R^2:', avg_train_r2)\n",
        "print('Average Training RMSE:', avg_train_rmse)\n",
        "print('Average Training Index of Agreement:', avg_train_index_of_agreement)\n",
        "\n",
        "val_r2=r2_score(y_val,val_pred)\n",
        "print('\\n Validation value of r2 score:',val_r2)\n",
        "\n",
        "# Evaluation metrics for testing set\n",
        "avg_test_mse = np.mean(test_mse_list)\n",
        "avg_test_r2 = np.mean(test_r2_list)\n",
        "avg_test_rmse = np.mean(test_rmse_list)\n",
        "avg_test_index_of_agreement = np.mean(test_index_of_agreement_list)\n",
        "print('\\nAverage Testing MSE:', avg_test_mse)\n",
        "print('Average Testing R^2:', avg_test_r2)\n",
        "print('Average Test RMSE:', avg_test_rmse)\n",
        "print('Average Testing Index of Agreement:', avg_test_index_of_agreement)"
      ],
      "metadata": {
        "id": "zdPx4r8zpPnt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33bd2f37-ec92-4651-b656-67eefac2cbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Training MSE: 0.708332969854166\n",
            "Average Training R^2: 0.8893068777766981\n",
            "Average Training RMSE: 0.8412470076159853\n",
            "Average Training Index of Agreement: 0.9704238555734953\n",
            "\n",
            "Best h value based on R^2: 150\n",
            "\n",
            " Validation value of r2 score: 0.804239566490819\n",
            "\n",
            "Average Testing MSE: 2.7108883755186803\n",
            "Average Testing R^2: 0.735112114273032\n",
            "Average Test RMSE: 1.6437395502667667\n",
            "Average Testing Index of Agreement: 0.9160572308244896\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}